#!/usr/bin/env python3
"""
æµ‹è¯•OpenAI APIå…¼å®¹æ¨¡å‹çš„é›†æˆ
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.external_model_service import ExternalModelService
from app.schemas.external_model_schemas import ExternalModelTest, APIType
from app.core.database import get_db

async def test_openai_api():
    """æµ‹è¯•OpenAI APIå…¼å®¹æ€§"""
    
    print("ğŸ§ª æµ‹è¯•OpenAI APIå…¼å®¹æ€§...")
    
    # è·å–æ•°æ®åº“ä¼šè¯
    db = next(get_db())
    service = ExternalModelService(db)
    
    # æµ‹è¯•æ•°æ®
    test_configs = [
        {
            "name": "OpenAI API (example)",
            "api_type": APIType.OPENAI,
            "api_url": "https://api.openai.com/v1/chat/completions",
            "model_id": "gpt-3.5-turbo",
            "api_key": "your-openai-api-key-here"
        },
        {
            "name": "Local Ollama with OpenAI API",
            "api_type": APIType.OPENAI,
            "api_url": "http://localhost:11434/v1/chat/completions",
            "model_id": "llama3.1:latest",
            "api_key": None
        },
        {
            "name": "OpenWebUI API (example)",
            "api_type": APIType.OPENWEBUI,
            "api_url": "http://localhost:3000/api/chat/completions",
            "model_id": "llama3.1:latest",
            "api_key": None
        }
    ]
    
    for config in test_configs:
        print(f"\nğŸ“¡ æµ‹è¯•é…ç½®: {config['name']}")
        print(f"   APIç±»å‹: {config['api_type'].value}")
        print(f"   APIåœ°å€: {config['api_url']}")
        print(f"   æ¨¡å‹ID: {config['model_id']}")
        print(f"   éœ€è¦APIå¯†é’¥: {'æ˜¯' if config['api_key'] else 'å¦'}")
        
        # æ„å»ºæµ‹è¯•è¯·æ±‚
        test_request = ExternalModelTest(
            api_type=config['api_type'],
            api_url=config['api_url'],
            model_id=config['model_id'],
            api_key=config['api_key']
        )
        
        try:
            # æ‰§è¡Œæµ‹è¯•
            result = await service.test_model(test_request)
            
            if result.success:
                print(f"   âœ… æµ‹è¯•æˆåŠŸ: {result.message}")
                if result.response_time:
                    print(f"   â±ï¸ å“åº”æ—¶é—´: {result.response_time:.2f}ç§’")
            else:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {result.message}")
                if result.error:
                    print(f"   ğŸ” é”™è¯¯è¯¦æƒ…: {result.error}")
                    
        except Exception as e:
            print(f"   ğŸ’¥ æµ‹è¯•å¼‚å¸¸: {str(e)}")
    
    print("\nğŸ¯ APIå…¼å®¹æ€§éªŒè¯:")
    print("1. OpenAI API: æ ‡å‡†çš„ChatGPT APIæ ¼å¼")
    print("   - ç«¯ç‚¹: /v1/chat/completions")
    print("   - è®¤è¯: Bearer token")
    print("   - æ ¼å¼: standard OpenAI ChatCompletion")
    print("   - ç¤ºä¾‹: https://api.openai.com/v1/chat/completions")
    print("   - ç¤ºä¾‹: http://localhost:11434/v1/chat/completions (Ollama)")
    
    print("\n2. OpenWebUI API: OpenWebUIå®ä¾‹çš„APIæ ¼å¼")
    print("   - ç«¯ç‚¹: /api/chat/completions")
    print("   - è®¤è¯: Bearer token (å¯é€‰)")
    print("   - æ ¼å¼: OpenWebUI compatible")
    print("   - ç¤ºä¾‹: http://localhost:3000/api/chat/completions")
    
    print("\nâœ¨ ä½¿ç”¨è¯´æ˜:")
    print("- åœ¨å¤–éƒ¨æ¨¡å‹ç®¡ç†é¡µé¢é€‰æ‹©æ­£ç¡®çš„APIç±»å‹")
    print("- OpenAI APIç±»å‹æ”¯æŒ:")
    print("  â€¢ å®˜æ–¹OpenAI API")
    print("  â€¢ ä»»ä½•OpenAIå…¼å®¹çš„API (å¦‚Ollamaçš„OpenAIå…¼å®¹ç«¯ç‚¹)")
    print("  â€¢ å…¶ä»–å…¼å®¹OpenAIæ ¼å¼çš„ç¬¬ä¸‰æ–¹æœåŠ¡")
    print("- OpenWebUI APIç±»å‹æ”¯æŒ:")
    print("  â€¢ OpenWebUIå®ä¾‹")
    print("  â€¢ å…¶ä»–å…¼å®¹OpenWebUIæ ¼å¼çš„æœåŠ¡")
    
    db.close()

if __name__ == "__main__":
    asyncio.run(test_openai_api()) 